{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surgical-kruger",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to inspect model fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rotary-houston",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/laurafontanesi/git/rlssm/docs/notebooks/DDM.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mrlssm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutility\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_model_results\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# load non-hierarchical DDM fit:\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m model_fit_ddm \u001B[38;5;241m=\u001B[39m \u001B[43mload_model_results\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/laurafontanesi/git/rlssm/docs/notebooks/DDM.pkl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# load non-hierarchical LBA fit:\u001B[39;00m\n\u001B[1;32m      7\u001B[0m model_fit_lba \u001B[38;5;241m=\u001B[39m load_model_results(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/laurafontanesi/git/rlssm/docs/notebooks/LBA_2A.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/rlssm/rlssm/utility/utils.py:8\u001B[0m, in \u001B[0;36mload_model_results\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model_results\u001B[39m(filename):\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124;03m\"\"\"Load model results from pickle.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/laurafontanesi/git/rlssm/docs/notebooks/DDM.pkl'"
     ]
    }
   ],
   "source": [
    "from rlssm.utility.utils import load_model_results\n",
    "\n",
    "# load non-hierarchical DDM fit:\n",
    "model_fit_ddm = load_model_results('/Users/laurafontanesi/git/rlssm/docs/notebooks/DDM.pkl')\n",
    "\n",
    "# load non-hierarchical LBA fit:\n",
    "model_fit_lba = load_model_results('/Users/laurafontanesi/git/rlssm/docs/notebooks/LBA_2A.pkl')\n",
    "\n",
    "# load hierarchical RL fit:\n",
    "model_fit_rl = load_model_results('/Users/laurafontanesi/git/rlssm/docs/notebooks/hierRL_2A.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-reviewer",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-transformation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The posterior samples are stored in `samples`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-bargain",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_ddm.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-bulletin",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_rl.samples.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-persian",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can simply plot the model's posteriors using `plot_posteriors`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-hungarian",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_ddm.plot_posteriors();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-ferry",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default, 95% HDIs are shown, but you can also choose to have the posteriors without intervals or BCIs, and change the alpha level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-musical",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_rl.plot_posteriors(show_intervals='BCI', alpha_intervals=.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-automation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Trial-level\n",
    "\n",
    "Depending on the model specification, you can also extract certain trial-level parameters as numpy ordered dictionaries of n_samples X n_trials shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-studio",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_ddm.trial_samples['drift_t'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-tribune",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_ddm.trial_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-korea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_lba.trial_samples.keys() # for the LBA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-shore",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the case of a RL model fit on choices alone, you can extract the log probability of accuracy=1 for each trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-address",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_rl.trial_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-accountability",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_rl.trial_samples['log_p_t'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-victor",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Posterior predictives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-better",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With `get_posterior_predictives_df` you get posterior predictives as pandas DataFrames of `n_posterior_predictives` X `n_trials` shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-positive",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pp = model_fit_rl.get_posterior_predictives_df(n_posterior_predictives=1000)\n",
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-sentence",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the DDM, you have additional parameters to tweak the DDM simulations, and you get a DataFrame with a hierarchical column index,  for RTs and for accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-transsexual",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pp = model_fit_ddm.get_posterior_predictives_df(n_posterior_predictives=100, dt=.001)\n",
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-island",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also have posterior predictive summaries with `get_posterior_predictives_summary`.\n",
    "\n",
    "Only mean accuracy for RL models fit on choices alone, and also mean RTs, skewness and quantiles for lower and upper boundaries for models fitted on RTs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-silicon",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_rl.get_posterior_predictives_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-saint",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_ddm.get_posterior_predictives_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-lithuania",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also specify which quantiles you are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-project",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_lba.get_posterior_predictives_summary(n_posterior_predictives=200, quantiles=[.1, .5, .9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-anger",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, you can get summary for grouping variables (e.g., experimental conditions, trial blocks, etc.) in your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-stage",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_lba.get_grouped_posterior_predictives_summary(n_posterior_predictives=200,\n",
    "                                                        grouping_vars=['block_label'],\n",
    "                                                        quantiles=[.3, .5, .7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-jewel",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot posterior predictives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-plumbing",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can plot posterior predictives similarly, both **ungrouped** (across all trials) or **grouped** (across conditions, trial blocks, etc.plot_mean_posterior_predictives).\n",
    "\n",
    "For RT models, you have both **mean plots**, and **quantile plots**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-appraisal",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_ddm.plot_mean_posterior_predictives(n_posterior_predictives=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-rainbow",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Quantile plots have 2 main visualization options, \"shades\" and \"lines\", and you can specify again which quantiles you want, which in tervals and alpha levels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-missouri",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_lba.plot_quantiles_posterior_predictives(n_posterior_predictives=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-belief",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_lba.plot_quantiles_posterior_predictives(n_posterior_predictives=200,\n",
    "                                                   kind='shades',\n",
    "                                                   quantiles=[.1, .5, .9]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-collapse",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fit_lba.plot_quantiles_grouped_posterior_predictives(\n",
    "    n_posterior_predictives=100,\n",
    "    grouping_var='block_label',\n",
    "    kind='shades',\n",
    "    quantiles=[.1, .3, .5, .7, .9]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-tobacco",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define new grouping variables:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = model_fit_rl.data_info['data']\n",
    "\n",
    "# add a column to the data to group trials across learning blocks\n",
    "data['block_bins'] = pd.cut(data.trial_block, 8, labels=np.arange(1, 9))\n",
    "\n",
    "# add a column to define which choice pair is shown in that trial\n",
    "data['choice_pair'] = 'AB'\n",
    "data.loc[(data.cor_option == 3) & (data.inc_option == 1), 'choice_pair'] = 'AC'\n",
    "data.loc[(data.cor_option == 4) & (data.inc_option == 2), 'choice_pair'] = 'BD'\n",
    "data.loc[(data.cor_option == 4) & (data.inc_option == 3), 'choice_pair'] = 'CD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-migration",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,8))\n",
    "\n",
    "model_fit_rl.plot_mean_grouped_posterior_predictives(grouping_vars=['block_bins'], n_posterior_predictives=500, ax=axes[0])\n",
    "\n",
    "model_fit_rl.plot_mean_grouped_posterior_predictives(grouping_vars=['block_bins', 'choice_pair'], \n",
    "                                                     n_posterior_predictives=500, ax=axes[1])\n",
    "\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}